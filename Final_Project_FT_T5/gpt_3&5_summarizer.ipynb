{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning for Topic News Title Summarization \n",
    "\n",
    "- In the era of digital information, the volume of news content available to readers has grown exponentially, making it increasingly challenging for individuals to stay informed without becoming overwhelmed. The project's primary goal is to leverage machine learning (ML) techniques for the effective summarization of news articles, aiming to improve the efficiency, accuracy, and readability of these summaries, allowing readers to grasp the essence of news stories without dedicating extensive time to reading full articles.\n",
    "\n",
    "- The stakeholders of this project can be individual readers, news organizations, educational sectors, and potentially government bodies reliant on swift and accurate information dissemination. Improved news summarization models can transform media consumption by providing accessible, succinct summaries of complex news stories, thereby enhancing public knowledge and engagement. Additionally, in broader vew, enhanced news summarization techniques could pave the way for similar advancements in summarizing other forms of text, such as academic literature, legal documents, and social media feeds.\n",
    "\n",
    "- Potential Model We will Explore:\n",
    "    - Bert summarization\n",
    "    - Fint tune T5-small\n",
    "    - GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "client = OpenAI(base_url=\"https://openai.vocareum.com/v1\", api_key=\"voc-194620361116581275266466216d217dafc7.78572946\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_set.csv', sep=',')\n",
    "test_df['content'] = test_df['content'].apply(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title_gpt3_5(content_list: list):\n",
    "    title_list = []\n",
    "    for content in tqdm(content_list):\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a title for the following content: \" + content},\n",
    "        ]\n",
    "        )\n",
    "        title_list.append(completion.choices[0].message.content)\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1217/1217 [23:16<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/test_set_summary_gpt3_5.csv'):\n",
    "    print('Start Generating Title on GPT-3.5 turbo')\n",
    "    content_list = test_df['content'].tolist()\n",
    "    title_list = generate_title_gpt3_5(content_list)\n",
    "    test_df['pred_title'] = title_list\n",
    "    test_df = test_df[['data_id', 'title', 'pred_title']]\n",
    "    test_df.to_csv('data/test_set_summary_gpt3_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load the Predicted Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load the generated titles from GPT-3.5\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('data/test_set_summary_gpt3_5.csv'):\n",
    "    print('Successfully load the generated titles from GPT-3.5')\n",
    "    gpt_df = pd.read_csv('data/test_set_summary_gpt3_5.csv', sep=',')\n",
    "else:\n",
    "    print('Failed to load the generated titles from GPT-3.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df['title'] = gpt_df['title'].apply(lambda x: x.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_df['pred_title'] = gpt_df['pred_title'].apply(lambda x: x.replace('\"', ''))\n",
    "gpt_df['pred_title'] = gpt_df['pred_title'].apply(lambda x: x.replace('Title: ', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See original title and GPT generated title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best party games for adults: The super fun board games, cards and quizzes to entertain your friends with in 2019\n",
      "Unplugged Fun: Best Board Games for Adults in the Digital Era\n"
     ]
    }
   ],
   "source": [
    "# See original title and GPT generated title\n",
    "print(gpt_df.iloc[0, 1])\n",
    "print(gpt_df.iloc[0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.3274146371663341,\n",
       " 'rouge2': 0.12480174759073806,\n",
       " 'rougeL': 0.27322813674959034,\n",
       " 'rougeLsum': 0.27299407173559675}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Rouge Score\n",
    "rouge.compute(predictions=gpt_df['pred_title'], references=gpt_df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93c670902e04166b259f66d61ad7a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eabc19358b4671b3938d5f4342fd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 52.83 seconds, 23.03 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Calculate BERTScore\n",
    "P, R, F1 = score(gpt_df['pred_title'].to_list(), gpt_df['title'].to_list(), lang='en', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8777\n",
      "Recall: 0.8820\n",
      "F1: 0.8796\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {P.mean():.4f}')\n",
    "print(f'Recall: {R.mean():.4f}')\n",
    "print(f'F1: {F1.mean():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
